# -*- coding: utf-8 -*-
"""Trabalho Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dm3F_ts7OJUWdS6e69l2w7FOFqBo-_We

# Importação e Preparação do Dataset

# Nova seção

Importação
"""

import seaborn as sns
sns.set_style('whitegrid')
import statsmodels.api as sm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pandas.plotting import scatter_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score,recall_score,silhouette_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from scipy.cluster.hierarchy import dendrogram
from sklearn.cluster import KMeans,DBSCAN, AgglomerativeClustering
!pip install scikit-learn-extra
from sklearn_extra.cluster import KMedoids
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import SGDClassifier

"""Carregando dataset"""

# O Student Performance inclui dois datasets para duas disciplinas diferentes, 
# matemática e português. Usaremos o de portugues que possui mais amostras 
# (todos os alunos) e usaremos somente ele para evitar análise duplicada.

# Para facilitar o uso dos algoritmos, a coluna com o atributo foco que é a nota
# final foi posta como sendo a primeira coluna. Além disso, já no dataset as 
# notas foram normalizadas em 3 faixas de desempenho, convertendo-as em 0, 1 ou 
# 2 (ruim, mediano e bom desempenho respectivamente). Originalmenter as notas 
# iam de 0 a 20. Assim:
# 0 - 9 = desempenho ruim (0)
# 10 - 14 = desempenho mediano (1)
# 15 - 20 = desempenho bom (2)

# Como a métrica para a nota final funciona diferente para essas escolas (que
# são portuguesas), vamos trabalhar sem levar em conta as duas primeiras notas,
# somente as notas finais.

dataset = "/content/student-por_otimizado.csv"

"""Transformando e otimizando dataframe"""

# Transformando dataset em um dataframe

dataframe = pd.read_csv(dataset, sep=';')

dataframe

# Para melhorar apresentar os dados, vamos renomear as colunas (atributos) para
# ficarem em português. Lembrando que as notas variam entre 0 e 20.

dataframe.columns = ['Desempenho_final','Escola','Sexo','Idade','Endereco','Tamanho_familia',
'Status_pais','Educacao_mae','Educacao_pai','Trabalho_mae','Trabalho_pai',
'Razao_escolha_escola','Guardiao','Tempo_ate_escola','Tempo_de_estudo',
'Repetencias_anteriores','Suporte_educacional','Suporte_familiar','Aulas_extra',
'Atividades_extra','Creche','Quer_fazer_faculdade','Internet_em_casa',
'Relacionamento','Qualidade_ambiente_familiar','Tempo_livre','Relacao_amigos',
'Alcool_semana','Alcool_fim_de_semana','Saude','Faltas']

dataframe

print(dataframe.describe()) #algumas analises gerais dos atributos numéricos

"""Divisão entre treinamento e teste"""

# Preparando dataset em treinamento (70%) e teste (30%)

X = dataframe.drop('Desempenho_final',axis=1)
y = dataframe.Desempenho_final
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.30, random_state=1)

print(X)
print("\n")
print(y)
print("\n")

print(X_train)
print("\n")
print(X_test)
print("\n")
print(Y_train)
print("\n")
print(Y_test)

# # Transformando nossa "tabela" em vetores para usarmos os algoritmos de
# # aprendizado de máquina

# vetor = dataframe.values #Todas as linhas e todas as colunas
# X = vetor[:,1:] #Todas as linhas e todas as colunas a partir da coluna 1, que
# # será a coluna com atributo foco (Desempenho_final)
# y = vetor[:,0] #Todas as linhas da coluna 0, que é atributo principal
# # (Desempenho Final)

# print(X)
# print("\n")
# print(y)
# print("\n")
# print(vetor)

# Nesse dataset temos dados na forma nominal, binários (yes/no) ou não. 
# Precisamos passar esses dados nesse formato par um formato numérico. Com a 
# função get_dummies convertemos os dados nominais em combinações de 0 e 1

X_train = pd.get_dummies(X_train)
X_test = pd.get_dummies(X_test)
X_train

"""# Algoritmos de Agrupamento (Clustering)

1) K-medoids
"""

# Trabalha com número de clusters como hiperparâmetro (serão aplicadas técnicas
# de otimização para determinar melhor "k"). Se baseia na distância, chutando
# valores iniciais dos centróides aleatoriamente igual uma das amostras.

model = KMedoids(n_clusters=2,init='k-medoids++', max_iter=1000).fit(X_train)
labels = model.labels_
centroids = model.cluster_centers_
print(labels)
print(centroids)

"""2) K-means"""

# Trabalha com número de clusters como hiperparâmetro (serão aplicadas técnicas
# de otimização para determinar melhor "k"). Se baseia na distância, chutando
# valores iniciais dos centróides como pontos espaciais aleatórios (diferente do
# k-medoids que tinha como centróide obrigatoriamente uma das amostras). 


model = KMeans(n_clusters=2, random_state=0).fit(X_train)
labels = model.labels_
print(labels)
print(model.cluster_centers_)

"""Método de Otimização) Silhouette"""

# Auxilia na determinação do hiperparâmetro k ótimo. Buscamos o caso ótimo em 
# as amostras estejam alocadas corretamente, ou seja, graficamente buscamos o
# k que indica o ponto mais alto do gráfico.

def silhouete_plot(results,method,clusters):
	g=plt.figure(1)
	plt.plot(list(results.keys()),list(results.values()),label='Silhouette Method',color='green')
	plt.ylabel('Silhouette Score', fontsize=18)
	plt.xlabel('Clusters', fontsize=20)
	plt.xticks(fontsize=18)
	plt.yticks(fontsize=18, rotation=0)
	plt.legend(loc='upper left', prop={'size': 15})
	plt.xlim((min(results.keys()),max(results.keys())))
	plt.grid(linestyle='dotted', linewidth=1)
	plt.show()
	best_k = max(results, key=results.get)
	print('Best k: ',best_k)

"""Método de Otimização) Elbow"""

# Auxilia na determinação do hiperparâmetro k ótimo. Precisamos identificar o 
# ponto onde há o "elbow", já que depois disso o k tende a estabilizar.


def elbow_plot(sse,method,clusters):
	maximum=max(sse.values())
	for key in sse:
		sse[key] = float(sse[key])/maximum

	g=plt.figure(2)
	plt.plot(list(sse.keys()),list(sse.values()),label='Elbow Method',color='blue',linestyle='dashed')
	plt.ylabel('SSE', fontsize=18)
	plt.xlabel('Clusters', fontsize=20)
	plt.xticks(fontsize=18)
	plt.yticks(fontsize=18, rotation=0)
	plt.legend(loc='upper right', prop={'size': 15})
	plt.xlim((min(sse.keys()),max(sse.keys())))
	plt.grid(linestyle='dotted', linewidth=1)
	plt.show()

# Busca do "k" ótimo com base nas técnicas de otimização.

start = 2;	end = 100;	step = 2; # variáveis a serem inseridas
num_clusters = list(range(start,end+step,step))
sse_silhouete = {}
sse_elbow = {}

for k in num_clusters:
  print("Testing k = ",k)
  # Definir K-medoids ou K-means
  model = KMedoids(n_clusters=k,init='k-medoids++', max_iter=1000).fit(X_train)
  sse_elbow[k] = model.inertia_ # erro quadrático médio (SSE)
  predictions = model.predict(X_train)
  sse_silhouete[k] = silhouette_score(X_train, predictions)

print (sse_elbow)
print (sse_silhouete)
elbow_plot(sse_elbow,method='k-medoids',clusters=str(end))
silhouete_plot(sse_silhouete,method='k-medoids',clusters=str(end))

"""3) Hierárquico Aglomerativo (bottom-up)"""

# Devemos introduzir os hiperparâmetros de função de ligação (linkage) e
# a técnica de distância entre pontos utilizada (affinity). Geramos assim um
# dendograma.

model = AgglomerativeClustering(affinity = 'euclidean', linkage ='ward').fit(X_train)
#n_clusters = None 
labels = model.labels_
print(labels)

"""4) DBSCAN"""

# Baseado em densidade, tem como hiperparâmetros a vizinhança do ponto (eps) e
# o número de amostras para que dado seja definido como agrupamento 
# (min_samples). 

model = DBSCAN(eps=5, min_samples=2).fit(X_train)
labels = model.labels_
print(labels)
print(set(labels))

"""# Algoritmos de Classificação e Regressão

Validação Cruzada e Métricas para Recuperação de Informação
"""

# Introduzindo os algoritmos de Classificação e Regressão

models = []
models.append(('KNN', KNeighborsClassifier()))
models.append(('Naive_Bayes', GaussianNB()))
models.append(('Arvore_de_Decisao', DecisionTreeClassifier()))
models.append(('Floresta_Aleatoria', RandomForestClassifier()))
models.append(('AdaBoost', AdaBoostClassifier()))
models.append(('Gradient_Boosting_Classificacao', SGDClassifier()))
models.append(('Maquina_Vetor_Suporte (SVM)', SVC(gamma='auto')))
models.append(('Regressao_Logistica', LogisticRegression(solver='liblinear', multi_class='ovr')))
models.append(('LDA', LinearDiscriminantAnalysis()))

# Validação Cruzada: buscamos avaliar a performance dos algoritmos selecionados
# com base no nosso conjunto de treinamento (todas as amostras) e selecionando
# um avaliador para compararmos (acurácia)

results = []
names = []
for name, model in models:
	kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
	cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
	results.append(cv_results)
	names.append(name)
	print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))

 # Nesse caso a "saída" vai ser o avaliador para cada algoritmo junto com a
 # margem de erro associada.

# Métricas de Recuperação de Informação. Agora não vamos comparar com mais
# avaliadores, e vamos usar o conjunto com as amostras de teste.Então como saída
# vamos ter uma comparação entre o conjunto de treinamento e de teste. Quanto
# mais próximo de 1.0, melhor.

for name, model in models:
  model.fit(X_train, Y_train)
  y_pred = model.predict(X_test)
  print(name)
  print ("Acuracia: " + str(accuracy_score(Y_test,y_pred)))
  print ("Recall: " + str(recall_score(Y_test,y_pred,average='micro')))
  print ("Precisao: " + str(precision_score(Y_test,y_pred,average='macro')))
  print ("F1-Score: " + str(f1_score(Y_test,y_pred,average='micro')))
  print("\n")

# Árvore de Decisão

msl=[]
for i in range(1,58):
    tree = DecisionTreeClassifier(min_samples_leaf=i)
    t= tree.fit(X_train, Y_train)
    ts=t.score(X_test, Y_test)
    msl.append(ts)
msl = pd.Series(msl)
msl.where(msl==msl.max()).dropna()

# final model
tree = DecisionTreeClassifier(min_samples_leaf=17)
t= tree.fit(X_train, Y_train)
print("Decisioin Tree Model Score" , ":" , t.score(X_train, Y_train) , "," , 
      "Cross Validation Score" ,":" , t.score(X_test, Y_test))

"""1) Floresta Aleatória"""

# Floresta Aleatória

# ne=[]
# for i in range(1,58):
#     forest = RandomForestClassifier()
#     f = forest.fit(X_train, Y_train)
#     fs = f.score(X_test, Y_test)
#     ne.append(fs)
# ne = pd.Series(ne)
# ne.where(ne==ne.max()).dropna()

# ne=[]
# for i in range(1,58):
#     forest = RandomForestClassifier(n_estimators=36, min_samples_leaf=i)
#     f = forest.fit(X_train, Y_train)
#     fs = f.score(X_test, Y_test)
#     ne.append(fs)
# ne = pd.Series(ne)
# ne.where(ne==ne.max()).dropna()

forest = RandomForestClassifier(n_estimators=36, min_samples_leaf=2)
f = forest.fit(X_train, Y_train)
print("Random Forest Model Score" , ":" , f.score(X_train, Y_train) , "," ,
      "Cross Validation Score" ,":" , f.score(X_test, Y_test))